*****Running model = BertForMaskedLM.from_pretrained(args.loadmodel)*****
The Initial Date = 6-14
bert is training which based on corpus ./train_data/duie_ner_train_1_spo_noWork_text.txt
The log information is saved in : ./log/bert/duie_ner_train_1_spo_noWork_text_20220614202904_rbtl1_train_log.txt
epoch = 0
*****For ee == 0, gg == 0:*****
*****special_tokens_mask: tensor([[ True, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],
        [ True, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,  True],
        [ True, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],
        [ True, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False,  True,  True,  True,  True,  True,  True,  True,  True]])*****
*****np.shape(special_tokens_mask): torch.Size([4, 90])*****
*****probability_matrix: tensor([[0.0000, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.0000],
        [0.0000, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500, 0.1500,
         0.1500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])*****
*****np.shape(probability_matrix): torch.Size([4, 90])*****
*****masked_indices: tensor([[False,  True,  True, False, False, False, False, False,  True,  True,
         False, False,  True, False, False, False, False,  True,  True, False,
          True, False,  True, False, False,  True,  True, False, False,  True,
         False, False, False,  True, False, False, False, False, False, False,
          True, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False],
        [False, False, False, False,  True, False, False, False,  True, False,
         False, False, False,  True, False, False, False, False, False, False,
          True,  True, False, False, False, False, False, False, False, False,
         False,  True, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False,  True, False,  True, False, False, False, False,  True,
         False, False, False, False,  True,  True, False, False,  True, False,
         False,  True, False, False, False,  True, False, False, False, False,
         False, False,  True, False, False, False, False, False, False, False],
        [False, False, False, False, False,  True, False, False, False, False,
         False, False, False, False, False, False, False, False,  True, False,
         False, False, False,  True, False, False, False, False,  True, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False,  True, False, False, False, False,  True,
          True, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False],
        [False, False, False, False,  True, False, False, False, False, False,
         False,  True, False, False, False, False, False, False, False, False,
         False, False, False, False, False,  True, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False,  True, False, False, False, False, False, False, False,  True,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False,  True, False, False,  True, False,  True, False, False, False,
         False, False, False, False, False, False, False, False, False, False]])*****
*****np.shape(masked_indices): torch.Size([4, 90])*****
*****labels: tensor([[ -100,   677, 16919,  -100,  -100,  -100,  -100,  -100,  8707,  2399,
          -100,  -100,   122,  -100,  -100,  -100,  -100, 14801,  2768,  -100,
           671,  -100, 15456,  -100,  -100,  8024,   677,  -100,  -100, 15396,
          -100,  -100,  -100, 15208,  -100,  -100,  -100,  -100,  -100,  -100,
         16180,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],
        [ -100,  -100,  -100,  -100, 16246,  -100,  -100,  -100,  1304,  -100,
          -100,  -100,  -100, 18840,  -100,  -100,  -100,  -100,  -100,  -100,
          8024,  3727,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100, 18779,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  1298,  -100, 14150,  -100,  -100,  -100,  -100, 18364,
          -100,  -100,  -100,  -100, 16902,  5052,  -100,  -100, 13746,  -100,
          -100,  8024,  -100,  -100,  -100,  2110,  -100,  -100,  -100,  -100,
          -100,  -100,  8024,  -100,  -100,  -100,  -100,  -100,  -100,  -100],
        [ -100,  -100,  -100,  -100,  -100,  7270,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  8285,  -100,
          -100,  -100,  -100,   712,  -100,  -100,  -100,  -100, 17567,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100, 15513,  -100,  -100,  -100,  -100, 16372,
         20089,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],
        [ -100,  -100,  -100,  -100,  3299,  -100,  -100,  -100,  -100,  -100,
          -100,  2339,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  1814,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100, 13746,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  9086,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  8230,  -100,  -100,  3791,  -100, 13864,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100]])*****
*****np.shape(labels): torch.Size([4, 90])*****
*****indices_replaced: tensor([[False,  True,  True, False, False, False, False, False, False,  True,
         False, False,  True, False, False, False, False,  True,  True, False,
          True, False,  True, False, False, False,  True, False, False,  True,
         False, False, False,  True, False, False, False, False, False, False,
          True, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False],
        [False, False, False, False,  True, False, False, False,  True, False,
         False, False, False,  True, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False,  True, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False,  True, False,  True, False, False, False, False,  True,
         False, False, False, False,  True,  True, False, False,  True, False,
         False,  True, False, False, False,  True, False, False, False, False,
         False, False,  True, False, False, False, False, False, False, False],
        [False, False, False, False, False,  True, False, False, False, False,
         False, False, False, False, False, False, False, False,  True, False,
         False, False, False,  True, False, False, False, False,  True, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False,  True, False, False, False, False,  True,
          True, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False],
        [False, False, False, False,  True, False, False, False, False, False,
         False,  True, False, False, False, False, False, False, False, False,
         False, False, False, False, False,  True, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False,  True, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False,  True, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False]])*****
*****np.shape(indices_replaced): torch.Size([4, 90])*****
*****indices_random: tensor([[False, False, False, False, False, False, False, False,  True, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
          True,  True, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False]])*****
*****np.shape(indices_random): torch.Size([4, 90])*****
*****random_words: tensor([[ 9707,   975,  3667, 15203,  7584, 10221, 11372,  8965,  3520,   352,
          3725, 18605, 19586,  3651, 20680, 16452,   614,  2064,  9662, 18339,
         10141,  2242, 13128,  5002,  8105,  9933, 13913,   780,  6853, 20775,
          1884,   901,  4267,  9651, 12949, 16917, 17939, 20863,  2204, 21089,
          2888, 16325,  7270,  4862,   960, 16397, 15307,   799, 10338,  2381,
          6000, 14324,  1337, 19877,  6439, 15445,  1092, 18698,  3603,  3565,
         13193,  8155,  6375,  5130,  2265, 16047,  8390, 10692, 14313, 19360,
          5580, 18285,  9805, 20342,  9803, 19649,  2962,  7819,  8887, 21019,
         13082, 12227,  7489, 11890, 11574,  6544,  1409,  2529,  9185, 17635],
        [18076, 18487, 20481,  2818, 15687, 19343,  8889, 20255,  6259, 17133,
          5780,  5149, 12115,  1428,  8124, 13508,  8874,  3106, 14741,  3439,
         14270,  9635, 16107,  4830,  3914, 19847,  3050,  1059, 15218, 11190,
          3406, 20968, 18365,  8709, 14676, 11995, 11291,  4601, 10377,  2487,
          4600,  7301,  6014, 10614,  7885, 17610, 20429, 15855,  4390,  1172,
         20673, 10827,   742, 12091, 16529,  9930, 10329,  7422, 13483, 10385,
          6720, 17446,  5050, 11094,  2027,   589,  1267,  9600, 10296, 17871,
         19546, 20891, 10289, 16696,  4052, 15075,  6797, 19117, 18242, 14069,
          6326,  6370, 16305,  3639, 14478,  3351, 17961,   811, 17753,  2736],
        [ 1910,  9413,  9694, 16435,  8079, 10355,  4641,  4434,  3610, 14078,
          5036, 11396, 14365, 20720, 13554,  4282, 13652, 20243, 14315,  9855,
          7873,  6773, 11186, 20161, 12475,  9957,  8974, 20035,  7449,  5983,
          7777,  5776, 11518,  3441,  7255,  9161, 13380,  6599,  7966, 14860,
          9438, 19145, 11179, 11550, 10217, 17699,  2485,  8518,  1607,  4689,
         14317, 12404,  8917,  1590,   663,  8957, 14168, 18819,  3871,  8399,
         12995,  6551,  6604, 13639, 11205,  1132, 17628, 19210, 13967,   695,
           773, 16382,   893, 19131,   277,  8043, 13555, 17674, 16907, 16056,
          5205, 11646, 10570,  5098, 14562,  2274, 10496, 16379,  8088,  3545],
        [11909, 17193, 13409, 19457,  8638, 16009,  2161, 18551,  7404,  1771,
          4357,  4148,  1472,  4388, 14770, 19084, 19428, 17424, 19081,   676,
         13169,   515, 18908, 10882, 10502,  7547, 17830,  6901,  3940, 15695,
         19764,  2195, 15573,  3191,  9749,  3152,  8651,  9955, 10415,  3329,
         11434, 17728,  1579,  2887, 13098, 13538,  6479,  5933, 17843, 16901,
         10222,  3894, 13226, 16722,  3105, 13204,   637, 13278, 18203,   239,
          4581, 17816, 18025,  1217,  1681,  9188, 17528, 12422,  4185,  7570,
         14104, 20321, 19075,  5370, 14939, 14413, 14028,  2951,  8192,  7565,
          1063, 10725,  3454,  8751,  5711,  2826, 14220, 17396, 13852,  8707]])*****
*****np.shape(random_words): torch.Size([4, 90])*****
*****inputs: tensor([[  101,   103,   103,  4638,  3152, 14322,  1765, 16460,  3520,   103,
          8108,  3299,   103,  3189,  8024,  3173,   704,   103,   103, 18046,
           103, 14510,   103,   722, 20411,  8024,   103, 16919, 15413,   103,
         13839, 16209, 14322,   103,  2190,  1059, 15413,  5466, 15396,  2458,
           103,   102,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],
        [  101,  8020,  1298, 16232,   103, 15902,  6381, 18499,   103, 16209,
         15455,  8021,  4374,   103,  5042, 14382,  4374, 18840,  8024,  4511,
         14270,  9635, 16241,  8024,  8955,  2399,   125,  3299, 17552,  8024,
          3736,   103,  4012, 16919,   782,  8024,  8911,  2399,  8108,  3299,
          1057, 14111,  8024,  8974,  2399,   128,  3299,  1346, 14274,  2339,
         13925,  8024,   103, 13833,   103, 13746, 14977, 15167,  1093,   103,
         18200,  1093, 13746,  5307,   103,   103, 17472,   683,   103,  3684,
         13746,   103,  4777, 18012, 17552,   103, 14382,  8024,  1093, 15167,
          1300, 14951,   103,  3136, 16013,   510,  4777, 18012, 14504,   102],
        [  101,  1355, 15302,  2456, 19449,   103, 15185,   924, 20429, 18364,
         18336,  3300, 20418, 14119, 14442,  2768, 18046,   754,   103,  2399,
           126,  3299,  8024,   103, 19263,  4507,  1744, 15214,   103, 18438,
          1062, 14442,  5143, 18377,  1392, 18438,  4689,  4510, 14270, 14119,
         14442,  1139, 19655,  5299,   103,  8024,  3800, 14142,  6598,   103,
           103,   123,   102,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],
        [  101,  8201,  2399,  8108,   103,  8125,  3189,  1762,   756, 14355,
         17746,   103, 14612, 19178, 16181, 18109, 17472, 15286,  1359, 16348,
          1399, 17974,   711,   756, 14355,   103, 15889,  5390, 13746,  5500,
         13876,  3300, 20418, 14119, 14442,   117,   821, 13746, 16848, 13839,
          5852,   103, 15866, 17269,  3800, 14142, 14441,   131, 10830,  9086,
          9086,  8279,  9340,  9148,   117,  1062, 14442,  3800, 14142,  1765,
         14827,   711,   756, 14355, 17746,  3204, 16266, 15413,  3696, 18718,
          6662,  8230,  1384,   117,   103, 15194, 13864, 19191,   782,   131,
          6387, 20497,   102,     0,     0,     0,     0,     0,     0,     0]])*****
*****np.shape(inputs): torch.Size([4, 90])*****
*****inputs: {'input_ids': tensor([[  101,   103,   103,  4638,  3152, 14322,  1765, 16460,  3520,   103,
          8108,  3299,   103,  3189,  8024,  3173,   704,   103,   103, 18046,
           103, 14510,   103,   722, 20411,  8024,   103, 16919, 15413,   103,
         13839, 16209, 14322,   103,  2190,  1059, 15413,  5466, 15396,  2458,
           103,   102,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],
        [  101,  8020,  1298, 16232,   103, 15902,  6381, 18499,   103, 16209,
         15455,  8021,  4374,   103,  5042, 14382,  4374, 18840,  8024,  4511,
         14270,  9635, 16241,  8024,  8955,  2399,   125,  3299, 17552,  8024,
          3736,   103,  4012, 16919,   782,  8024,  8911,  2399,  8108,  3299,
          1057, 14111,  8024,  8974,  2399,   128,  3299,  1346, 14274,  2339,
         13925,  8024,   103, 13833,   103, 13746, 14977, 15167,  1093,   103,
         18200,  1093, 13746,  5307,   103,   103, 17472,   683,   103,  3684,
         13746,   103,  4777, 18012, 17552,   103, 14382,  8024,  1093, 15167,
          1300, 14951,   103,  3136, 16013,   510,  4777, 18012, 14504,   102],
        [  101,  1355, 15302,  2456, 19449,   103, 15185,   924, 20429, 18364,
         18336,  3300, 20418, 14119, 14442,  2768, 18046,   754,   103,  2399,
           126,  3299,  8024,   103, 19263,  4507,  1744, 15214,   103, 18438,
          1062, 14442,  5143, 18377,  1392, 18438,  4689,  4510, 14270, 14119,
         14442,  1139, 19655,  5299,   103,  8024,  3800, 14142,  6598,   103,
           103,   123,   102,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],
        [  101,  8201,  2399,  8108,   103,  8125,  3189,  1762,   756, 14355,
         17746,   103, 14612, 19178, 16181, 18109, 17472, 15286,  1359, 16348,
          1399, 17974,   711,   756, 14355,   103, 15889,  5390, 13746,  5500,
         13876,  3300, 20418, 14119, 14442,   117,   821, 13746, 16848, 13839,
          5852,   103, 15866, 17269,  3800, 14142, 14441,   131, 10830,  9086,
          9086,  8279,  9340,  9148,   117,  1062, 14442,  3800, 14142,  1765,
         14827,   711,   756, 14355, 17746,  3204, 16266, 15413,  3696, 18718,
          6662,  8230,  1384,   117,   103, 15194, 13864, 19191,   782,   131,
          6387, 20497,   102,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])}*****
*****np.shape(inputs): (3,)*****
*****np.shape(inputs['input_ids']): torch.Size([4, 90])*****
*****np.shape(inputs['token_type_ids']): torch.Size([4, 90])*****
*****np.shape(inputs['attention_mask']): torch.Size([4, 90])*****
*****labels: tensor([[ -100,   677, 16919,  -100,  -100,  -100,  -100,  -100,  8707,  2399,
          -100,  -100,   122,  -100,  -100,  -100,  -100, 14801,  2768,  -100,
           671,  -100, 15456,  -100,  -100,  8024,   677,  -100,  -100, 15396,
          -100,  -100,  -100, 15208,  -100,  -100,  -100,  -100,  -100,  -100,
         16180,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],
        [ -100,  -100,  -100,  -100, 16246,  -100,  -100,  -100,  1304,  -100,
          -100,  -100,  -100, 18840,  -100,  -100,  -100,  -100,  -100,  -100,
          8024,  3727,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100, 18779,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  1298,  -100, 14150,  -100,  -100,  -100,  -100, 18364,
          -100,  -100,  -100,  -100, 16902,  5052,  -100,  -100, 13746,  -100,
          -100,  8024,  -100,  -100,  -100,  2110,  -100,  -100,  -100,  -100,
          -100,  -100,  8024,  -100,  -100,  -100,  -100,  -100,  -100,  -100],
        [ -100,  -100,  -100,  -100,  -100,  7270,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  8285,  -100,
          -100,  -100,  -100,   712,  -100,  -100,  -100,  -100, 17567,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100, 15513,  -100,  -100,  -100,  -100, 16372,
         20089,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],
        [ -100,  -100,  -100,  -100,  3299,  -100,  -100,  -100,  -100,  -100,
          -100,  2339,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  1814,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100, 13746,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  9086,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  8230,  -100,  -100,  3791,  -100, 13864,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100]])*****
*****np.shape(labels): torch.Size([4, 90])*****
*****For ee == 0, gg == 0:*****
*****outputs.logits: tensor([[[ 2.2914,  3.4809,  2.8232,  ...,  1.0108,  2.9387,  1.7097],
         [ 0.4045,  0.9248,  2.1267,  ...,  0.0251,  1.9206,  1.0293],
         [ 0.0917,  1.1614,  0.9470,  ..., -0.2867,  1.7304,  1.5689],
         ...,
         [-0.5288,  0.0751, -1.0665,  ..., -1.7606,  0.8929, -0.1065],
         [-0.8336, -0.0720, -0.7491,  ..., -2.0671,  0.6251, -0.0304],
         [-0.6383, -0.1066, -0.7148,  ..., -2.0136,  0.8409, -0.1822]],

        [[ 2.3145,  3.6065,  3.2829,  ...,  0.3061,  3.3463,  2.0039],
         [ 0.7209, -0.2312,  0.7440,  ..., -1.9648,  0.3019,  0.1849],
         [-1.3912, -0.2860, -0.3510,  ..., -1.3381,  0.3124,  0.1696],
         ...,
         [ 0.9631,  1.8453,  1.0954,  ..., -0.8405,  2.8758,  0.7251],
         [-2.5244, -1.8047, -1.8086,  ..., -5.1367, -0.1272, -1.7577],
         [ 2.3149,  3.6063,  3.2842,  ...,  0.3065,  3.3472,  2.0043]],

        [[ 2.5667,  3.2478,  3.1845,  ...,  0.2994,  3.4483,  2.4121],
         [-1.5074, -0.0918,  0.9486,  ..., -0.6479,  0.6354,  0.9780],
         [ 3.5274,  2.9556,  1.9895,  ...,  1.9328,  3.8263,  1.8312],
         ...,
         [ 0.3259,  1.3727,  0.4878,  ...,  0.0269,  2.1353,  1.4996],
         [-0.0762,  1.0920,  0.8565,  ..., -0.0153,  1.7658,  1.3784],
         [-0.1409,  0.5070,  0.4099,  ..., -0.1470,  1.8825,  1.1438]],

        [[ 2.8482,  2.6314,  2.6212,  ..., -0.3886,  2.7982,  1.9474],
         [ 2.2921,  1.8143,  0.5249,  ..., -1.2455,  2.8099,  1.7079],
         [ 0.8356,  0.7759,  0.3683,  ..., -1.4221,  1.6535, -0.6432],
         ...,
         [-0.6438, -1.3192, -0.9868,  ..., -2.3795,  0.8986, -0.9908],
         [-0.7996, -1.2287, -0.1781,  ..., -2.1501,  0.7501, -0.8332],
         [-0.3230, -1.0900, -0.5557,  ..., -2.1581,  1.2685, -0.6920]]],
       device='cuda:0', grad_fn=<AddBackward0>)*****
*****np.shape(outputs.logits): torch.Size([4, 90, 21128])*****
*****outputs.loss: 10.568047523498535*****
*****np.shape(outputs.loss): torch.Size([])*****
*****masked_label: tensor([  677, 16919,  8707,  2399,   122, 14801,  2768,   671, 15456,  8024,
          677, 15396, 15208, 16180, 16246,  1304, 18840,  8024,  3727, 18779,
         1298, 14150, 18364, 16902,  5052, 13746,  8024,  2110,  8024,  7270,
         8285,   712, 17567, 15513, 16372, 20089,  3299,  2339,  1814, 13746,
         9086,  8230,  3791, 13864], device='cuda:0')*****
*****np.shape(masked_label): torch.Size([44])*****
*****masked_pre: tensor([11006,  6698,  5598,  7487, 13165,  4435,  2312,  9898,  2118,  7487,
        10941, 10343,  6069,  8934,  1797, 11059,  5536,   417,  5701,  7559,
         6512,  2312,  7158,  7158,  7487,  7966,  7487,  7487,   344,  7935,
         1622,  9230,  2088,   395,  2534,  6012,  1189,  1028,  3450,  2884,
         2961,  1102,  7162,  2431], device='cuda:0')*****
*****np.shape(masked_pre): torch.Size([44])*****
